{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "613eaa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BBC_end_phrases = [\"Follow BBC\", \"Follow Essex news\", \"@bbc\", \"Instagram, external\", \"@BBCAfrica\", \"Sign up for our morning newsletter\", \"Listen to highlights from\"]\n",
    "Metro_end_phrases = [\"@metro.co.uk\", \"Arrow\\nMORE\", \"Metro.co.uk\", \"Follow Metro Sport\"]\n",
    "\n",
    "def scraper(row=None, url=None, src=None, get_images=False):\n",
    "    if not row is None:\n",
    "        url = row[\"link\"]\n",
    "        src = row[\"source\"]\n",
    "        \n",
    "    try:\n",
    "        raw = requests.get(url)\n",
    "        soup = BeautifulSoup(raw.content, \"lxml\")\n",
    "\n",
    "        if src == \"BBC\":\n",
    "            article_by_ptag = soup.find(\"article\").find_all(\"p\")\n",
    "            article = []\n",
    "            for i in article_by_ptag:\n",
    "                text = i.get_text()\n",
    "                \n",
    "                flag = False\n",
    "                for word in BBC_end_phrases:\n",
    "                    if word in text and not flag:\n",
    "                        flag = True\n",
    "\n",
    "                if \"PromoHeadline\" in str(i) or flag:\n",
    "                    break\n",
    "                article.append(i.get_text())\n",
    "\n",
    "        elif src == \"Daily mail\": ### this catches junk text for some articles\n",
    "            fulltext = soup.find(\"div\", {\"itemprop\": \"articleBody\"}).get_text(separator=\"\\n\", strip=True)\n",
    "            article = fulltext.split(\"\\n\")\n",
    "        \n",
    "        elif src == \"Metro\": \n",
    "            article_by_ptag = soup.find(\"div\", {\"class\": \"article__content\"}).find_all(\"p\")\n",
    "            article = []\n",
    "            for i in article_by_ptag:\n",
    "                text = i.get_text()\n",
    "                \n",
    "                flag = False\n",
    "                for word in Metro_end_phrases:\n",
    "                    if word in text and not flag:\n",
    "                        flag = True\n",
    "                if flag: break\n",
    "\n",
    "                if 'target=\"_blank\"' in str(i):\n",
    "                    pass\n",
    "                else:\n",
    "                    article.append(text)\n",
    "\n",
    "        else:\n",
    "            print(\"{} can't be scraped at the moment, sorry\".format(src))\n",
    "            article = None  \n",
    "\n",
    "        return article\n",
    "\n",
    "    except Exception as error:\n",
    "        print(url, error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/migrant-dehumanization.csv\")[[\"source\", \"link\"]]\n",
    "df[\"source\"] = df[\"source\"].replace({1: \"Metro\", 2: \"Financial Times\", 3: \"Daily mail\", 4: \"BBC\"})\n",
    "dfs = []\n",
    "\n",
    "to_scrape = [\"BBC\", \"Daily mail\", \"Metro\"]\n",
    "drop_duplicates = True\n",
    "scrape = True\n",
    "export = True\n",
    "\n",
    "if drop_duplicates:\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "if scrape:\n",
    "    for site in to_scrape:\n",
    "        data = df[df[\"source\"] == site].apply(scraper, axis=1)\n",
    "        dfs.append(data)\n",
    "\n",
    "if export:\n",
    "    for i in range(len(dfs)):\n",
    "        df = dfs[i].dropna()\n",
    "        df.to_csv(\"data/corpus/{}_corpus.txt\".format(to_scrape[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
